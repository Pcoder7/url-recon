name: Url recon from waybackarchive & filtering

on:
  workflow_dispatch:

permissions:
  contents: write

jobs:
  generate_matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set_matrix.outputs.matrix }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Generate Matrix from domains.txt
        id: set_matrix
        run: |
          if [ ! -f domains.txt ]; then
            echo "domains.txt file not found!"
            exit 1
          fi
          # Create a JSON array from non-empty lines in domains.txt
          matrix=$(jq -R -s -c 'split("\n") | map(select(length > 0))' domains.txt)
          echo "Matrix: $matrix"
          echo "matrix=$matrix" >> $GITHUB_OUTPUT

  scan:
    needs: generate_matrix
    runs-on: ubuntu-latest
    strategy:
      matrix:
        domain: ${{ fromJson(needs.generate_matrix.outputs.matrix) }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
      

      - name: Debug files & Go env
        run: |
          pwd
          ls -la
          git ls-files | sed -n '1,300p'
          find . -type f -name 'go.mod' -o -name 'go.sum' || true
          go env GOMOD || true

      - name: Ensure go.mod exists (auto-init if missing)
        run: |
          if [ -f go.mod ]; then
            echo "go.mod exists at repo root"
            go env GOMOD
          else
            echo "go.mod not found â€” attempting to init module from git remote"
            origin=$(git config --get remote.origin.url || true)
            if [ -z "$origin" ]; then
              modpath="example.com/temp/module"
              echo "no git remote found; using temporary module path: $modpath"
            else
              # convert git@github.com:owner/repo.git -> https://github.com/owner/repo
              modpath=$(echo "$origin" \
                | sed -E 's#^git@([^:]+):#https://\1/#' \
                | sed -E 's#^ssh://##' \
                | sed -E 's#^https?://##' \
                | sed -E 's#\.git$##' \
                | sed -E 's#^#https://#')
              # sanitize resulting URL (make it module path form)
              modpath=$(echo "$modpath" | sed -E 's#https?://##')
              echo "derived module path: $modpath"
            fi

            # init module and tidy (may add go.sum)
            go mod init "$modpath"
            # tidy to populate go.sum (can fail if imports unreachable)
            go mod tidy || true
            echo "Created go.mod; CI will proceed but please commit go.mod/go.sum to repo for reproducible builds."
            go env GOMOD || true
          fi
          

      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.23'


      - name: Cache Go modules and build cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/go-build
            ~/go/pkg/mod
          key: ${{ runner.os }}-go-${{ hashFiles('**/go.sum') }}
          restore-keys: |
            ${{ runner.os }}-go-
          
      
      - name: Update & Install Dependencies
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y curl git jq unzip

      - name: Download modules
        run: |
          go env GOMOD
          go mod download

      - name: Build binary
        run: |
          
          go build -o spiderkxss main.go
          ./spiderkxss --help || true
        
      - name: Create Results Directory for ${{ matrix.domain }}
        run: |
           mkdir -p results/${{ matrix.domain }}
           rm -f results/${{ matrix.domain }}/urls/*.txt || true

      - name: Install uforall
        run: |
           wget https://github.com/rix4uni/uforall/releases/download/v0.0.2/uforall-linux-amd64-0.0.2.tgz
           tar -xvzf uforall-linux-amd64-0.0.2.tgz
           rm -rf uforall-linux-amd64-0.0.2.tgz
           mv uforall ~/go/bin/uforall
           echo $GOPATH
          
      - name: Install Tools
        run: |

            go install github.com/tomnomnom/waybackurls@latest
            go install github.com/lc/gau/v2/cmd/gau@latest
            go install github.com/hahwul/dalfox/v2@latest
            go install -v github.com/tomnomnom/anew@latest
            go install github.com/Emoe/kxss@latest          
            pip install waymore
            pip install urless
            pipx install uro
      

      - name: URL Enumeration 
        run: |
            
            DOMAIN="${{ matrix.domain }}"
            OUTDIR="results/${DOMAIN}/urls"
            mkdir -p "$OUTDIR"
            BLACKLIST_EXT=".js,.bak,.css,.ico,.jpg,.jpeg,.png,.bmp,.svg,.img,.gif,.mp4,.flv,.ogv,.webm,.webp,.mov,.mp3,.m4a,.m4p,.scss,.tif,.tiff,.ttf,.otf,.woff,.woff2,.bmp,.ico,.eot,.htc,.rtf,.swf,.image"
            URO_BLACKLIST="css ico jpg jpeg png bmp svg img gif mp4 flv ogv webm webp mov mp3 m4a m4p scss tif tiff ttf otf woff woff2 bmp ico eot htc rtf swf image js"
            # 1. Waybackurls: archived URLs
            #  waybackurls "$DOMAIN" > "$OUTDIR/waybackurls.txt"
            
            # 2. gau: combined source URLs, filter out images
            gau --subs  --providers wayback,commoncrawl --o "$OUTDIR/gau.txt" "$DOMAIN"

            cat "$DOMAIN" | uforall -t archive -silent | anew -q "$OUTDIR/uforall.txt"
      
            # 3. waymore: deep crawl with archive mode U
             #  waymore -i "$DOMAIN" -mode U -oU "$OUTDIR/waymore.txt"
      
            # 4. Combine and dedupe all URL lists
            cat "$OUTDIR/waybackurls.txt" "$OUTDIR/uforall.txt" "$OUTDIR/gau.txt" "$OUTDIR/waymore.txt" \
                | sort -u > "$OUTDIR/all_urls.txt"
             
             # count all urls
            echo "=========== Count All Urls ========="
            cat "$OUTDIR/all_urls.txt" | wc -l
            
            echo "======================================="
            # 5. Filter image and js extensions, then select only URLs with parameters
            cat "$OUTDIR/all_urls.txt" \
                | uro -b "$URO_BLACKLIST" --filters hasparams -o "$OUTDIR/parameterized_urls.txt"
                
           
               # 6. Further clean with urless (drop blogs, JS libs, etc.) 
            cat "$OUTDIR/parameterized_urls.txt" \
                | urless -nb -fe "$BLACKLIST_EXT" -fk blog,article,static,asset,assets,news,bootstrap,jquery,captcha,node_modules -o "$OUTDIR/all_filtered.txt"    

            echo "=========== Count Filtered Urls Only ========="
              # count all filtered urls
            cat "$OUTDIR/all_filtered.txt" | wc -l

            echo "======================================="

            #cat "$OUTDIR/all_filtered.txt" | dalfox pipe --skip-grepping  --skip-bav --skip-mining-all --skip-mining-dict --skip-mining-dom --skip-xss-scanning --skip-headless --only-discovery \
             #  --skip-grepping --worker 30 --max-cpu 2 --user-agent "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/111.0" --timeout 30 --no-spinner \
              # --no-color --debug -o "$OUTDIR/$DOMAIN-dalfoxlog.txt"
            cat "$OUTDIR/all_filtered.txt" | ./spiderkxss -c 40 -d 0.3-0.7 --debug --rotate-agent 5-10 --ua-file user-agents.txt  | anew  -q "$OUTDIR/$DOMAIN-dalfox.txt"
           # cat "$OUTDIR/$DOMAIN-dalfoxlog.txt" |grep -A 1 'Reflected .* param =>' --color=never |  anew -q "$OUTDIR/$DOMAIN-dalfox.txt"    

       # â€¦ after your extraction steps â€¦
  
      - name: Compare against last run via Git HEAD
        id: compare_urls
        run: |
          DOMAIN="${{ matrix.domain }}"
          BASE="results/${DOMAIN}/urls"
          NEW_FILE="$BASE/all_filtered.txt"
          PREV=$(mktemp)
  
          # 1) Grab the previous version of all_filtered.txt from HEAD (if it exists)
          git show HEAD:"$NEW_FILE" 2>/dev/null | sort -u > "$PREV" || touch "$PREV"
  
          # 2) Sort today's version
          sort -u "$NEW_FILE" > "${NEW_FILE}.sorted"
  
          # 3) Lines in today's sorted file not in the previous = truly new URLs
          comm -23 "${NEW_FILE}.sorted" "$PREV" > "$BASE/new_urls.txt"
  
          # 4) Set a GitHub Actions output flag
          if [ -s "$BASE/new_urls.txt" ]; then
            echo "has_new_urls=true" >> $GITHUB_OUTPUT
          else
            echo "has_new_urls=false" >> $GITHUB_OUTPUT
          fi
        

      - name: Upload filtered URLs artifact
        uses: actions/upload-artifact@v4
        with:
          name: filtered-urls-${{ matrix.domain }}
          path: results/${{ matrix.domain }}/urls/$DOMAIN-dalfox.txt
          retention-days: 1

      # â”€â”€â”€ Install gf & pattern files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Install gf and Gf-Patterns
        run: |
          # install gf CLI
          go install github.com/tomnomnom/gf@latest
          # pull down community JSONs
          git clone https://github.com/1ndianl33t/Gf-Patterns.git
          # prepare your ~/.gf dir and copy examples
          mkdir -p ~/.gf
          mv Gf-Patterns/*.json ~/.gf
          # expose GF_PATH if needed
          echo "GF_PATH=$HOME/.gf" >> $GITHUB_ENV

      
        # â”€â”€â”€ Extract vulnerability parameters via gf â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Extract SSRF, sqli, lfi, debug_logic & idor parameters
        run: |
          DOMAIN="${{ matrix.domain }}"
          BASE="results/${{ matrix.domain }}/urls"
          INPUT="$BASE/all_filtered.txt"

          # produce one file per pattern
          cat "$INPUT" | gf ssrf          > "$BASE/ssrf_params.txt"
          cat "$INPUT" | gf sqli          > "$BASE/sqli_params.txt"
          cat "$INPUT" | gf lfi           > "$BASE/lfi_params.txt"
          cat "$INPUT" | gf debug_logic   > "$BASE/debug_logic_params.txt"
          cat "$INPUT" | gf idor          > "$BASE/idor_params.txt"      
     
      - name: Install notify
        env: 
          DISCORD_WEBHOOK: ${{ secrets.URLRECON_WEBHOOK }}
        run: |
          go install -v github.com/projectdiscovery/notify/cmd/notify@latest
          mkdir -p ~/.config/notify/
          cat <<EOF > ~/.config/notify/provider-config.yaml
              # Write provider config with our Discord webhook
          discord:
            - id: "fuzz"
              discord_channel: "subdomain-scan"
              discord_format: "{{data}}"
              discord_webhook_url: "${{ secrets.URLRECON_WEBHOOK }}"
          EOF
          echo "$HOME/go/bin" >> $GITHUB_PATH
          # display and show provider-config.yaml file
          cat ~/.config/notify/provider-config.yaml  

      - name: Show notify config
        run: | 
          echo "$URLRECON_WEBHOOK"
          sed -e 's/.*/&/' ~/.config/notify/provider-config.yaml
        env:
          DISCORD_WEBHOOK: ${{ secrets.URLRECON_WEBHOOK }}
          
            #  Notify Discord for each pattern if there are findings
      - name: Notify Discord vulnerability params for ${{ matrix.domain }}
        env:
          DISCORD_WEBHOOK: ${{ secrets.URLRECON_WEBHOOK }}
        run: |
          DOMAIN="${{ matrix.domain }}"
          DATE=$(date +"%d-%m-%Y")
          BASE="results/${DOMAIN}/urls"

           # loop over each pattern's file
          for PAT in ssrf sqli lfi debug_logic idor; do
            FILE="$BASE/${PAT}_params.txt"
            if [ -s "$FILE" ]; then
              # header for this pattern
              echo -e "ðŸ”” New ${PAT^^} parameters for ${DOMAIN}\nðŸ“… Date: ${DATE}" \
                | notify -id fuzz
              # attach the findings file
              notify -bulk -id fuzz -data "$FILE" -char-limit 1000000 -no-color
            fi
          done
      
      - name: Notify Discord of New URLs for ${{ matrix.domain }}
        if: steps.compare_urls.outputs.has_new_urls == 'true'
        run: |
            DOMAIN="${{ matrix.domain }}"
            DATE=$(date +"%d-%m-%Y")
            FILE="results/${DOMAIN}/urls/new_urls.txt"
            COUNT=$(wc -l < "$FILE")
      
            # Send file if >50, else one bulk message
            if [ "$COUNT" -gt 50 ]; then
              # header message
              echo -e "ðŸ”” New URLs for ${{ matrix.domain }}\nðŸ“… Date: $DATE" \
                | notify -id fuzz
              # file attachment
              notify -bulk -id fuzz -data "$FILE" -char-limit 1000000 -no-color -silent
            else
              # bulk message
              {
                echo "ðŸ”” New URLs for ${{ matrix.domain }}"
                echo "ðŸ“… Date: $DATE"
                echo
                cat "$FILE"
              } | notify -bulk -id fuzz
            fi

      - name: Notify Discord of Dalfox scan for ${{ matrix.domain }}
        env:
          DISCORD_WEBHOOK: ${{ secrets.URLRECON_WEBHOOK }}
        run: |
            DOMAIN="${{ matrix.domain }}"
            DATE=$(date +"%d-%m-%Y")
            FILE="results/${DOMAIN}/urls/$DOMAIN-dalfox.txt"
            COUNT=$(wc -l < "$FILE")
      
            # Send file if >50, else one bulk message
            if [ "$COUNT" -gt 50 ]; then
              # header message
              echo -e "ðŸ”” New URLs for ${{ matrix.domain }}\nðŸ“… Date: $DATE" \
                | notify -id fuzz
              # file attachment
              notify -bulk -id fuzz -data "$FILE" -char-limit 1000000 -no-color -silent
            else
              # bulk message
              {
                echo "ðŸ”” New URLs for ${{ matrix.domain }}"
                echo "ðŸ“… Date: $DATE"
                echo
                cat "$FILE"
              } | notify -bulk -id fuzz
            fi

